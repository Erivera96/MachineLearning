{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataCleaning_ClassifyingStates.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjjHB5D9XnEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob as gl\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG2n1BFXX34P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extension = \"csv\"\n",
        "\n",
        "file_names = np.array([\"air_quality.csv\", \"car_insurance_fees.csv\", \"car_registration_fees.csv\", \"cost_of_living.csv\",\"crime_arsen.csv\", \"debt.csv\", \"education_rank.csv\", \"employment.csv\", \"ethnicity.csv\", \"homeless.csv\",\"internet_speed.csv\", \"labor_force.csv\", \"population.csv\", \"recreation.csv\", \"taxes.csv\", \"test_scores.csv\"])\n",
        "\n",
        "#file_names = np.array([\"air_quality.csv\", \"car_insurance_fees.csv\"])\n",
        "\n",
        "files = np.array(['https://raw.githubusercontent.com/Erivera96/MachineLearning/master/ClassifyingStates/' + fn for fn in file_names])\n",
        "df1 = pd.read_csv(files[0])\n",
        "df = []\n",
        "for i in range(0,len(file_names)):\n",
        "    daframe = pd.read_csv(files[i]).sort_values(by=['State'],ascending=True, axis=0)\n",
        "    indices = list(daframe.index)\n",
        "    dic = dict(zip(indices,daframe['State'][indices]))\n",
        "    daframe = daframe.rename(index=dic)\n",
        "    df.append(daframe)\n",
        "\n",
        "states = pd.concat(df, axis=1,sort=False).drop('State',axis=1)\n",
        "states = states.loc[:,~states.columns.duplicated()]\n",
        "states = states.drop(['avgCost', 'registrationNote', 'American Indian/Alaska Native', 'Native Hawaiian/Other Pacific Islander', 'Total', 'rank', 'Percent'], axis=1)\n",
        "states = states.drop('District of Columbia', axis=0)\n",
        "\n",
        "states.to_csv(\"states_data.csv\", index=False, encoding='utf-8-sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zkzte-DPg7ds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8faXop33I5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.sum(np.sum(states.isna()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}