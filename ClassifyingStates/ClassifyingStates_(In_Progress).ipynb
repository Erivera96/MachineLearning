{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClassifyingStates (In Progress).ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TSflhWlPEBl",
        "colab_type": "text"
      },
      "source": [
        "#Data Cleaning Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjjHB5D9XnEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob as gl\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG2n1BFXX34P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extension = \"csv\"\n",
        "file_names = np.array([\"air_quality.csv\", \"car_insurance_fees.csv\", \"car_registration_fees.csv\", \"cost_of_living.csv\",\"crime_arsen.csv\", \"debt.csv\", \"education_rank.csv\", \"employment.csv\", \"ethnicity.csv\", \"homeless.csv\",\"internet_speed.csv\", \"labor_force.csv\", \"population.csv\", \"recreation.csv\", \"taxes.csv\", \"test_scores.csv\"])\n",
        "\n",
        "files = np.array(['https://raw.githubusercontent.com/Erivera96/MachineLearning/master/ClassifyingStates/MessyData/' + fn for fn in file_names])\n",
        "\n",
        "df = []\n",
        "for i in range(0,len(file_names)):\n",
        "    daframe = pd.read_csv(files[i]).sort_values(by=['State'],ascending=True, axis=0)\n",
        "    indices = list(daframe.index)\n",
        "    dic = dict(zip(indices, daframe['State'][indices]))\n",
        "    daframe = daframe.rename(index=dic)\n",
        "    df.append(daframe)\n",
        "states = pd.concat(df, axis=1,sort=False)\n",
        "states = states.drop(\"District of Columbia\", axis=0)\n",
        "states = states.reset_index()\n",
        "states = states.loc[:,~states.columns.duplicated()]\n",
        "states = states.drop(['index','avgCost', 'registrationNote', 'American Indian/Alaska Native', 'Native Hawaiian/Other Pacific Islander', 'Total', 'rank', 'Percent'], axis=1)\n",
        "\n",
        "#states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JblMi4KT5pMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states = states.rename(columns={'Pop':'Population', 'registrationCost':'CarRegistrationCost','costIndex':'CostIndex', 'costRank':'CostRank', 'groceryCost':'GroceryCost',\n",
        "                                'housingCost':'HousingCost','utilitiesCost':'UtilitiesCost','transportationCost':'TransportationCost',\n",
        "                                'miscCost':'MiscCost', 'homicideRate2017':'HomicideRate','firearmDeathRate':'FirearmDeathRate','firearmDeaths':'FirearmDeaths',\n",
        "                                'debt':'Debt','overallRank':'EducationRank','higherEducationRank':'HigherEducationRank','prek12Rank':'PreK12Rank',\n",
        "                                'employmentRate':'EmploymentRate','Two Or More Races':'MultiRace','totalHomeless':'TotalHomeless', 'totalHouseholds':'TotalHouseholds',\n",
        "                                'totalVeterans':'TotalVeterans','totalYoungAdults':'TotalYoungAdults','Pop2018':'Population2018','Pop2010':'Population2010',\n",
        "                                'growthSince2010':'GrowthSince2010','density':'Density', 'taxRank':'TaxRank', 'incomeTax':'IncomeTax', 'salesTax':'SalesTax',\n",
        "                                'propertyTax':'PropertyTax', 'averageACTScore':'AvgACTScore', 'meetingEnglish':'MetEnglish', 'meetingReading':'MetReading',\n",
        "                                'meetingMath':'MetMath', 'meetingScience':'MetScience'})\n",
        "\n",
        "column_order = ['State', 'Population', 'CostIndex', 'Debt', 'Growth', 'EmploymentRate', \n",
        "                'Density', 'CarRegistrationCost', 'CostRank', 'GroceryCost', 'HousingCost', 'UtilitiesCost',\n",
        "                'TransportationCost', 'MiscCost', 'HomicideRate', 'FirearmDeathRate','FirearmDeaths', 'PerCapita', \n",
        "                'EducationRank','HigherEducationRank', 'PreK12Rank', 'White', 'Black','Hispanic', 'Asian', \n",
        "                'MultiRace', 'TotalHomeless', 'TotalHouseholds','TotalVeterans', 'TotalYoungAdults', 'Population2018',\n",
        "                'Population2010', 'GrowthSince2010', 'AirQualityIndex', 'OutdoorRecreation', 'Retail', 'IndoorRecreation', 'Food', \n",
        "                'TaxRank', 'IncomeTax', 'SalesTax', 'PropertyTax', 'AvgACTScore', 'MetEnglish','MetReading', 'MetMath', 'MetScience']\n",
        "states = states.reindex(columns=column_order)\n",
        "\n",
        "# states.to_csv(\"US_states_data.csv\", index=False, encoding='utf-8-sig')\n",
        "states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8faXop33I5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.sum(np.sum(states.isna()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGWiue_3PJWi",
        "colab_type": "text"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT0LaaoxPDA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egyt-0BmxoMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.express as px\n",
        "df = px.data.tips()\n",
        "fig = px.histogram(states,x='Population')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei-QbaSHyY8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = px.scatter(states, x=\"State\", y=\"Population\", color=\"Debt\",\n",
        "                 size='Density')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kGGYKrg0ER2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Violin(y=states['IndoorRecreation'],\n",
        "                        box_visible=True,\n",
        "                        meanline_visible=True))\n",
        "fig.add_trace(go.Violin(y=states['OutdoorRecreation'],\n",
        "                        box_visible=True,\n",
        "                        meanline_visible=True))\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA-ykFCq3lnU",
        "colab_type": "text"
      },
      "source": [
        "#Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDwm0oe0wgap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states_copy = states.copy(deep=True)\n",
        "states_copy = states_copy.drop(['State','CostRank','EducationRank','HigherEducationRank','PreK12Rank','TaxRank'],axis=1)\n",
        "states_array = states_copy.to_numpy()\n",
        "states_array.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diKC7K4b3qGO",
        "colab_type": "text"
      },
      "source": [
        "##KMeans Clustering Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH4Qi5pEyO2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclid_dist(p1, p2):\n",
        "    retval = 0\n",
        "\n",
        "    for i in range(0,p1.shape[0]):\n",
        "        retval += (p1[i]-p2[i])**2\n",
        "    retval = np.sqrt(retval)\n",
        "\n",
        "    return retval\n",
        "\n",
        "\n",
        "def assign_to_cluster(P_row, centroids):\n",
        "    return np.argmin([euclid_dist(P_row, centroids[i,:]) for i in range(0, centroids.shape[0])])\n",
        "\n",
        "\n",
        "def calc_centroids(P, bins, k, bounds):\n",
        "\n",
        "    centroids = []\n",
        "    for i in range(0, k): # max bins+1 = k\n",
        "       points = np.array([P[j,:] for j in range(0,P.shape[0]) if bins[j] == i]) # gets all points for a single cluster\n",
        "\n",
        "       # if no points belong to this centroid, rerandomize the centroid, else calc with mean\n",
        "       if points.size == 0:\n",
        "           centroids.append(np.array([bounds[i,0] + (bounds[i,1]-bounds[i,0])*np.random.rand() for i in range(0,P.shape[1])]))\n",
        "       else:\n",
        "           centroids.append(np.array([np.mean(points[:,i]) for i in range(0, P.shape[1])])) \n",
        "    return np.array(centroids)\n",
        "\n",
        "# The K-means algorithm function\n",
        "def kmeans(P,k,eps=1e-4,max_iter=1e4):\n",
        "\n",
        "    # Initialize k centroids randomly\n",
        "    dims = P.shape[1] # find how many dimensions there are\n",
        "    bounds = bounds = np.array([(np.min(P[:,i]), np.max(P[:,i])) for i in range(0,dims)]) # find the min and max of each dimension\n",
        "    \n",
        "    centroids =  []\n",
        "    for i in range(0,k):\n",
        "        centroids.append(np.array([bounds[i,0] + (bounds[i,1] - bounds[i,0])*np.random.rand() for i in range(0,dims)]))\n",
        "    centroids = np.array(centroids)\n",
        "    \n",
        "    # Starting K-Means\n",
        "    num_points = P.shape[0]\n",
        "    bins = None\n",
        "    iter = 0\n",
        "    centroid_max_diff = np.inf\n",
        "\n",
        "    while iter < int(max_iter) and centroid_max_diff > eps:\n",
        "\n",
        "        # Step 1) want to assign data to centroids\n",
        "        bins = np.array([assign_to_cluster(P[row,:], centroids) for row in range(0,num_points)])\n",
        "\n",
        "        # Step 2) recalculate centroid position for every cluster\n",
        "        centroids_prime = calc_centroids(P, bins, k, bounds)\n",
        "        centroid_max_diff = np.max(np.abs(centroids_prime - centroids))\n",
        "        centroids = centroids_prime\n",
        "\n",
        "        # increment iter\n",
        "        iter += 1\n",
        "\n",
        "    return centroids,bins"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3Ra6G6N3u1q",
        "colab_type": "text"
      },
      "source": [
        "##Testing Mine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZWJ9Vj-auWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "centroids, bins = kmeans(states_array, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQmFImA8fdFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def myplot(k, bins, centroids, data, plt_type='hist'):\n",
        "    k = 3\n",
        "    f = plt.figure(figsize=(20,15))\n",
        "    for i in range(0,k):\n",
        "        points = data[bins == i]\n",
        "        for j in range(0,points.shape[1]):\n",
        "            plt.subplot(7,7,j+1)\n",
        "            if plt_type == 'scatter':\n",
        "                plt.scatter(points[:,0],points[:,j])\n",
        "                plt.scatter(centroids[:,0],centroids[:,j],color='black')\n",
        "            else:\n",
        "                plt.hist(points[:,j],alpha=0.5,bins=10)\n",
        "                plt.hist(centroids[:,j],color='black')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUPTUB_-30QN",
        "colab_type": "text"
      },
      "source": [
        "##Dimentionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9gO1ROxgfT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import eig\n",
        "\n",
        "def PCA(A): #Principal Component Analysis\n",
        "\n",
        "    # first want the mean of the columns of A\n",
        "    Mean_A = np.mean(np.transpose(A), axis=1)\n",
        "\n",
        "    # second, center the columns by subtracting the mean from them\n",
        "    Centered_A = A - Mean_A\n",
        "    \n",
        "    # now we need the coviariance of this centered matrix, the covariance is generalized and unnormalized\n",
        "    Cov_A = np.cov(np.transpose(Centered_A))\n",
        "\n",
        "    # now we can do the eigenvalue decomposition:\n",
        "    eigvals, eigvecs = eig(Cov_A)\n",
        "    print('\\nValues:\\n', eigvals)\n",
        "\n",
        "    retval = np.dot(np.transpose(eigvecs), np.transpose(Centered_A))\n",
        "\n",
        "    return np.transpose(retval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtsHT6nakPWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states_reduced = PCA(states_array)\n",
        "states_reduced"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLT-NgGzoDRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_up(A):\n",
        "\n",
        "    new_A = []\n",
        "    count = 0\n",
        "    A = np.transpose(A)\n",
        "\n",
        "    for col in range(0,A.shape[0]):\n",
        "        for row in range(0,A.shape[1]):\n",
        "\n",
        "            # if a row contains values smaller than 0.01, count them as bad\n",
        "            if np.abs(A[col][row]) <= 1e-2:\n",
        "                count += 1\n",
        "\n",
        "        # if more than two rows (rows being the states) have bad values, don't count that column        \n",
        "        if count <= 2:\n",
        "            new_A.append(np.array(A[col,:]))\n",
        "\n",
        "    return np.transpose(np.array(new_A))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVJBRKbcrIgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states_reduced_cleaned = clean_up(states_reduced)\n",
        "states_reduced_cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgADvkswrnFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(states_reduced_cleaned.shape)\n",
        "print(states_array.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB5c697A4A1a",
        "colab_type": "text"
      },
      "source": [
        "##Retesting My KMeans with reduced data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iftvc8nNybmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K = 3\n",
        "centroids2, bins2 = kmeans(states_reduced_cleaned,K)\n",
        "myplot(K,bins2, centroids2, states_reduced_cleaned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kywol3_p4Gwc",
        "colab_type": "text"
      },
      "source": [
        "##Testing against Pythons KMeans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt4zl3Wr0kXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY22dRR00w_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans_test = KMeans(n_clusters=K,init='random')\n",
        "python_version = kmeans_test.fit(states_reduced_cleaned)\n",
        "myplot(K, python_version.labels_, python_version.cluster_centers_,states_reduced_cleaned)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}