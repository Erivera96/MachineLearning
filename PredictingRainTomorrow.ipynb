{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PredictingRainTomorrow.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuC4EVXJ2x9w",
        "colab_type": "text"
      },
      "source": [
        "### Import the data and get a look at the datatypes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPf04wD4qC4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3bEyPztxILo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rainfall = pd.read_csv('https://raw.githubusercontent.com/Erivera96/MachineLearningExercises/master/weatherAUS.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7KwwymDxdmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rainfall.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbWzqwLmxlPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"The rainfall dataset has \",rainfall.shape[0],\" columns and \",rainfall.shape[1],\" rows.\")\n",
        "rainfall_dtypes = rainfall.dtypes\n",
        "print(\"And has the following datatypes:\\n\", rainfall_dtypes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvutE2K_251g",
        "colab_type": "text"
      },
      "source": [
        "###After looking at the datatypes, we decide what we don't want to keep: Date which doesn't contribute much information other than distinguishing days and risk_mm which was adviced to be dropped on the kaggle dataset page."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK10UO_Vy3-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rainfall_data = rainfall.drop(['Date','RISK_MM'],axis=1)\n",
        "print(rainfall_data.shape)\n",
        "\n",
        "features = rainfall_data.drop('RainTomorrow',axis=1)\n",
        "labels = rainfall_data['RainTomorrow']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in4G0PTO3Of8",
        "colab_type": "text"
      },
      "source": [
        "###After removing things, we split the features from the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMqTXd5D2OXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(features.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp-DA0pm79-K",
        "colab_type": "text"
      },
      "source": [
        "###We want to seperate now, the numerical data from the categorical to work on each seperately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVJStpqi5H2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_dtypes = features.dtypes\n",
        "\n",
        "# find which features are numerical and which are categorical,\n",
        "# this returns vectors of T or F\n",
        "bool_num = features_dtypes != 'object'\n",
        "bool_cat = features_dtypes == 'object'\n",
        "\n",
        "feat_names = features.columns # returns just the name\n",
        "\n",
        "num_feat = features[feat_names[bool_num]]\n",
        "cat_feat = features[feat_names[bool_cat]]\n",
        "\n",
        "print(\"There are \", features_dtypes.size,\" features, where \", sum(bool_num), \" are numerical and \", sum(bool_cat), \" are categorical\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op6ujHaD9UJ5",
        "colab_type": "text"
      },
      "source": [
        "####How many of those are nan for each category?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBOfUJo_7Daa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_of_features = features.shape[0]\n",
        "\n",
        "print(\"Percent N/A for Categorical:\")\n",
        "for feat in cat_feat:\n",
        "    print(feat,'\\t\\t',np.sum(cat_feat[feat].isna())/number_of_features*100)\n",
        "\n",
        "print(\"\\nPercent N/A for Numerical:\")\n",
        "for feat in num_feat:\n",
        "    print(feat, '\\t\\t',np.sum(num_feat[feat].isna())/number_of_features*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76dLh2w-_IGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NOTICE IN NUMERICAL FEATURES: Sunshine (and others) has so many empty records that \n",
        "# even if we fill with the mean or median, it would just not be accurate to do, \n",
        "# therefore, we will drop this feature (and the others) entirely.\n",
        "\n",
        "num_feat = num_feat.drop(['Evaporation','Sunshine', 'Cloud9am', 'Cloud3pm'], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDQAQwYSGGDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOTICE IN CATEGORICAL FEATURES: We have so few of the features being NANs, that\n",
        "# we may as well remove those records entirely, thus we will remove ALL the vectors \n",
        "# that contain nan in the categorical.\n",
        "\n",
        "master_bool = np.full((features.shape[0],),False,dtype=bool)\n",
        "for cfeat in cat_feat:\n",
        "    master_bool = np.any([master_bool,cat_feat[cfeat].isna()],axis=0)\n",
        "np.sum(master_bool)/features.shape[0]*100\n",
        "master_bool = np.logical_not(master_bool)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSnPnec7PEmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_feat = cat_feat[master_bool]\n",
        "num_feat = num_feat[master_bool]\n",
        "labels = labels[master_bool]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P06V2J7LPYbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Double check that we removed them\n",
        "np.sum(cat_feat.isna())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haPx3I2AAGJ3",
        "colab_type": "text"
      },
      "source": [
        "###Now, we take care of NANS in numerical but first we want to split our training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjDELeemARrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dDln4GfDAsP",
        "colab_type": "text"
      },
      "source": [
        "#### Remove NANS in the numerical data using an imputer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwRNebLDBeWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 37\n",
        "train_num, test_num = train_test_split(num_feat, random_state=seed, test_size=0.2)\n",
        "\n",
        "simputer = SimpleImputer(strategy='mean')\n",
        "simputer.fit(train_num)\n",
        "\n",
        "train_num_X = simputer.transform(train_num)\n",
        "test_num_X = simputer.transform(test_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCqR013pDjGC",
        "colab_type": "text"
      },
      "source": [
        "#### OneHot encode all the categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqjrlnedDogg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "onehot = OneHotEncoder(sparse=False)\n",
        "cat_feat_X = onehot.fit_transform(cat_feat)\n",
        "\n",
        "train_cat_X, test_cat_X = train_test_split(cat_feat_X, random_state=seed, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0l1IUtHTz78",
        "colab_type": "text"
      },
      "source": [
        "### Now combine the features: Train vs Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrYBxNi0TxiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X = np.hstack( (train_cat_X, train_num_X) )\n",
        "test_X = np.hstack( (test_cat_X, test_num_X) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCPnB0AwUKnf",
        "colab_type": "text"
      },
      "source": [
        "### Now we split the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMffsYp8UM46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = (labels == 'Yes').astype(int) # turn into numbers cause we can operate on numbers\n",
        "\n",
        "train_y, test_y = train_test_split(y, random_state=seed, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1uGG49BU4T4",
        "colab_type": "text"
      },
      "source": [
        "### Lets make sure our matricies shapes match"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnsSo34BU8rD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_X.shape)\n",
        "print(test_X.shape)\n",
        "print(train_y.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KuJiPcdVUmz",
        "colab_type": "text"
      },
      "source": [
        "###OK now we're cooking. We want to scale our data before we get to the meat of it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG9EOa-bVaec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "mms = MinMaxScaler()\n",
        "\n",
        "mms.fit(train_X)\n",
        "\n",
        "train_X = mms.transform(train_X)\n",
        "test_X = mms.transform(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggsEUj62WXGO",
        "colab_type": "text"
      },
      "source": [
        "### Now we do a logistic regression to find out if it will rain tomorrow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsAo7l7LWbOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression(solver='saga',random_state=seed)\n",
        "logreg.fit(train_X, train_y)\n",
        "\n",
        "logreg.score(test_X, test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}